{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-05-03T21:25:47.796558Z",
     "iopub.status.busy": "2025-05-03T21:25:47.796082Z",
     "iopub.status.idle": "2025-05-03T21:25:48.049164Z",
     "shell.execute_reply": "2025-05-03T21:25:48.048631Z",
     "shell.execute_reply.started": "2025-05-03T21:25:47.796535Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-03T21:25:48.050415Z",
     "iopub.status.busy": "2025-05-03T21:25:48.050071Z",
     "iopub.status.idle": "2025-05-03T21:25:51.114871Z",
     "shell.execute_reply": "2025-05-03T21:25:51.113870Z",
     "shell.execute_reply.started": "2025-05-03T21:25:48.050397Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'RPG-DiffusionMaster'...\n",
      "remote: Enumerating objects: 854, done.\u001b[K\n",
      "remote: Counting objects: 100% (125/125), done.\u001b[K\n",
      "remote: Compressing objects: 100% (99/99), done.\u001b[K\n",
      "remote: Total 854 (delta 83), reused 50 (delta 26), pack-reused 729 (from 1)\u001b[K\n",
      "Receiving objects: 100% (854/854), 65.74 MiB | 50.69 MiB/s, done.\n",
      "Resolving deltas: 100% (144/144), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/YangLing0818/RPG-DiffusionMaster\n",
    "# !cd RPG-DiffusionMaster\n",
    "# # !conda create -n RPG python==3.9\n",
    "# # !conda activate RPG\n",
    "# # !pip install -r requirements.txt\n",
    "# !git clone https://github.com/huggingface/diffusers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-03T21:38:45.038940Z",
     "iopub.status.busy": "2025-05-03T21:38:45.038628Z",
     "iopub.status.idle": "2025-05-03T21:38:45.042880Z",
     "shell.execute_reply": "2025-05-03T21:38:45.042351Z",
     "shell.execute_reply.started": "2025-05-03T21:38:45.038914Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "os.chdir(\"/kaggle/working/RPG-DiffusionMaster\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-03T21:38:47.342757Z",
     "iopub.status.busy": "2025-05-03T21:38:47.342466Z",
     "iopub.status.idle": "2025-05-03T21:38:47.479304Z",
     "shell.execute_reply": "2025-05-03T21:38:47.478346Z",
     "shell.execute_reply.started": "2025-05-03T21:38:47.342736Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__asset__\t    matrix.py\t RegionalDiffusion_base.py\t     RPG.py\n",
      "cross_attention.py  mllm.py\t RegionalDiffusion_playground.ipynb  template\n",
      "diffusers\t    __pycache__  RegionalDiffusion_xl.py\n",
      "LICENSE\t\t    README.md\t requirements.txt\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-03T21:25:51.259660Z",
     "iopub.status.busy": "2025-05-03T21:25:51.259394Z",
     "iopub.status.idle": "2025-05-03T21:25:56.943538Z",
     "shell.execute_reply": "2025-05-03T21:25:56.942838Z",
     "shell.execute_reply.started": "2025-05-03T21:25:51.259635Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'diffusers'...\n",
      "remote: Enumerating objects: 91614, done.\u001b[K\n",
      "remote: Counting objects: 100% (288/288), done.\u001b[K\n",
      "remote: Compressing objects: 100% (136/136), done.\u001b[K\n",
      "remote: Total 91614 (delta 212), reused 156 (delta 148), pack-reused 91326 (from 2)\u001b[K\n",
      "Receiving objects: 100% (91614/91614), 67.24 MiB | 31.79 MiB/s, done.\n",
      "Resolving deltas: 100% (67430/67430), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/huggingface/diffusers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-03T21:25:56.944712Z",
     "iopub.status.busy": "2025-05-03T21:25:56.944432Z",
     "iopub.status.idle": "2025-05-03T21:25:56.951611Z",
     "shell.execute_reply": "2025-05-03T21:25:56.950835Z",
     "shell.execute_reply.started": "2025-05-03T21:25:56.944683Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting requirements.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile requirements.txt\n",
    "accelerate==0.29.1\n",
    "asttokens==2.4.1\n",
    "attrs==23.2.0\n",
    "backcall==0.2.0\n",
    "beautifulsoup4==4.12.3\n",
    "bleach==6.1.0\n",
    "certifi==2024.2.2\n",
    "charset-normalizer==3.3.2\n",
    "comm==0.2.2\n",
    "decorator==5.1.1\n",
    "defusedxml==0.7.1\n",
    "diffusers==0.27.2\n",
    "docopt==0.6.2\n",
    "einops==0.7.0\n",
    "exceptiongroup==1.2.0\n",
    "executing==2.0.1\n",
    "fastjsonschema==2.19.1\n",
    "filelock==3.13.3\n",
    "fsspec==2024.3.1\n",
    "huggingface-hub==0.23.1\n",
    "idna==3.6\n",
    "importlib_metadata==7.1.0\n",
    "ipython==8.12.3\n",
    "ipywidgets==8.1.2\n",
    "jedi==0.19.1\n",
    "Jinja2==3.1.3\n",
    "jsonschema==4.21.1\n",
    "jsonschema-specifications==2023.12.1\n",
    "jupyter_client==8.6.1\n",
    "jupyter_core==5.7.2\n",
    "jupyterlab_pygments==0.3.0\n",
    "jupyterlab_widgets==3.0.10\n",
    "MarkupSafe==2.1.5\n",
    "matplotlib-inline==0.1.6\n",
    "mistune==3.0.2\n",
    "mpmath==1.3.0\n",
    "nbclient==0.10.0\n",
    "nbconvert==7.16.3\n",
    "nbformat==5.10.4\n",
    "networkx==3.2.1\n",
    "numpy>=1.23.0\n",
    "nvidia-cublas-cu12==12.1.3.1\n",
    "nvidia-cuda-cupti-cu12==12.1.105\n",
    "nvidia-cuda-nvrtc-cu12==12.1.105\n",
    "nvidia-cuda-runtime-cu12==12.1.105\n",
    "nvidia-cudnn-cu12==8.9.2.26\n",
    "nvidia-cufft-cu12==11.0.2.54\n",
    "nvidia-curand-cu12==10.3.2.106\n",
    "nvidia-cusolver-cu12==11.4.5.107\n",
    "nvidia-cusparse-cu12==12.1.0.106\n",
    "nvidia-nccl-cu12==2.19.3\n",
    "nvidia-nvjitlink-cu12==12.4.127\n",
    "nvidia-nvtx-cu12==12.1.105\n",
    "opencv-python==4.9.0.80\n",
    "packaging==24.0\n",
    "pandocfilters==1.5.1\n",
    "parso==0.8.4\n",
    "pexpect==4.9.0\n",
    "pickleshare==0.7.5\n",
    "pillow==10.3.0\n",
    "pipreqs==0.5.0\n",
    "platformdirs==4.2.0\n",
    "prompt-toolkit==3.0.43\n",
    "psutil==5.9.8\n",
    "ptyprocess==0.7.0\n",
    "pure-eval==0.2.2\n",
    "Pygments==2.17.2\n",
    "python-dateutil==2.9.0.post0\n",
    "PyYAML==6.0.1\n",
    "pyzmq==25.1.2\n",
    "referencing==0.34.0\n",
    "regex==2023.12.25\n",
    "requests==2.31.0\n",
    "rpds-py==0.18.0\n",
    "safetensors==0.4.2\n",
    "six==1.16.0\n",
    "soupsieve==2.5\n",
    "stack-data==0.6.3\n",
    "sympy==1.12\n",
    "tinycss2==1.2.1\n",
    "tokenizers==0.15.2\n",
    "torch==2.2.2\n",
    "torchvision==0.17.2\n",
    "tornado==6.4\n",
    "tqdm==4.66.2\n",
    "traitlets==5.14.2\n",
    "transformers==4.39.3\n",
    "triton==2.2.0\n",
    "typing_extensions==4.11.0rc1\n",
    "urllib3==2.2.1\n",
    "wcwidth==0.2.13\n",
    "webencodings==0.5.1\n",
    "widgetsnbextension==4.0.10\n",
    "xformers==0.0.25.post1\n",
    "yarg==0.1.9\n",
    "zipp==3.18.1\n",
    "peft==0.9.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-03T21:25:56.952582Z",
     "iopub.status.busy": "2025-05-03T21:25:56.952326Z",
     "iopub.status.idle": "2025-05-03T21:29:46.620304Z",
     "shell.execute_reply": "2025-05-03T21:29:46.619324Z",
     "shell.execute_reply.started": "2025-05-03T21:25:56.952559Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting accelerate==0.29.1 (from -r requirements.txt (line 1))\n",
      "  Downloading accelerate-0.29.1-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting asttokens==2.4.1 (from -r requirements.txt (line 2))\n",
      "  Downloading asttokens-2.4.1-py2.py3-none-any.whl.metadata (5.2 kB)\n",
      "Collecting attrs==23.2.0 (from -r requirements.txt (line 3))\n",
      "  Downloading attrs-23.2.0-py3-none-any.whl.metadata (9.5 kB)\n",
      "Requirement already satisfied: backcall==0.2.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 4)) (0.2.0)\n",
      "Collecting beautifulsoup4==4.12.3 (from -r requirements.txt (line 5))\n",
      "  Downloading beautifulsoup4-4.12.3-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting bleach==6.1.0 (from -r requirements.txt (line 6))\n",
      "  Downloading bleach-6.1.0-py3-none-any.whl.metadata (30 kB)\n",
      "Collecting certifi==2024.2.2 (from -r requirements.txt (line 7))\n",
      "  Downloading certifi-2024.2.2-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting charset-normalizer==3.3.2 (from -r requirements.txt (line 8))\n",
      "  Downloading charset_normalizer-3.3.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (33 kB)\n",
      "Requirement already satisfied: comm==0.2.2 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 9)) (0.2.2)\n",
      "Collecting decorator==5.1.1 (from -r requirements.txt (line 10))\n",
      "  Downloading decorator-5.1.1-py3-none-any.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: defusedxml==0.7.1 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 11)) (0.7.1)\n",
      "Collecting diffusers==0.27.2 (from -r requirements.txt (line 12))\n",
      "  Downloading diffusers-0.27.2-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting docopt==0.6.2 (from -r requirements.txt (line 13))\n",
      "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Collecting einops==0.7.0 (from -r requirements.txt (line 14))\n",
      "  Downloading einops-0.7.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting exceptiongroup==1.2.0 (from -r requirements.txt (line 15))\n",
      "  Downloading exceptiongroup-1.2.0-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting executing==2.0.1 (from -r requirements.txt (line 16))\n",
      "  Downloading executing-2.0.1-py2.py3-none-any.whl.metadata (9.0 kB)\n",
      "Collecting fastjsonschema==2.19.1 (from -r requirements.txt (line 17))\n",
      "  Downloading fastjsonschema-2.19.1-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting filelock==3.13.3 (from -r requirements.txt (line 18))\n",
      "  Downloading filelock-3.13.3-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting fsspec==2024.3.1 (from -r requirements.txt (line 19))\n",
      "  Downloading fsspec-2024.3.1-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting huggingface-hub==0.23.1 (from -r requirements.txt (line 20))\n",
      "  Downloading huggingface_hub-0.23.1-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting idna==3.6 (from -r requirements.txt (line 21))\n",
      "  Downloading idna-3.6-py3-none-any.whl.metadata (9.9 kB)\n",
      "Collecting importlib_metadata==7.1.0 (from -r requirements.txt (line 22))\n",
      "  Downloading importlib_metadata-7.1.0-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting ipython==8.12.3 (from -r requirements.txt (line 23))\n",
      "  Downloading ipython-8.12.3-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting ipywidgets==8.1.2 (from -r requirements.txt (line 24))\n",
      "  Downloading ipywidgets-8.1.2-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting jedi==0.19.1 (from -r requirements.txt (line 25))\n",
      "  Downloading jedi-0.19.1-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting Jinja2==3.1.3 (from -r requirements.txt (line 26))\n",
      "  Downloading Jinja2-3.1.3-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting jsonschema==4.21.1 (from -r requirements.txt (line 27))\n",
      "  Downloading jsonschema-4.21.1-py3-none-any.whl.metadata (7.8 kB)\n",
      "Collecting jsonschema-specifications==2023.12.1 (from -r requirements.txt (line 28))\n",
      "  Downloading jsonschema_specifications-2023.12.1-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting jupyter_client==8.6.1 (from -r requirements.txt (line 29))\n",
      "  Downloading jupyter_client-8.6.1-py3-none-any.whl.metadata (8.3 kB)\n",
      "Requirement already satisfied: jupyter_core==5.7.2 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 30)) (5.7.2)\n",
      "Requirement already satisfied: jupyterlab_pygments==0.3.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 31)) (0.3.0)\n",
      "Collecting jupyterlab_widgets==3.0.10 (from -r requirements.txt (line 32))\n",
      "  Downloading jupyterlab_widgets-3.0.10-py3-none-any.whl.metadata (4.1 kB)\n",
      "Collecting MarkupSafe==2.1.5 (from -r requirements.txt (line 33))\n",
      "  Downloading MarkupSafe-2.1.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
      "Collecting matplotlib-inline==0.1.6 (from -r requirements.txt (line 34))\n",
      "  Downloading matplotlib_inline-0.1.6-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting mistune==3.0.2 (from -r requirements.txt (line 35))\n",
      "  Downloading mistune-3.0.2-py3-none-any.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: mpmath==1.3.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 36)) (1.3.0)\n",
      "Collecting nbclient==0.10.0 (from -r requirements.txt (line 37))\n",
      "  Downloading nbclient-0.10.0-py3-none-any.whl.metadata (7.8 kB)\n",
      "Collecting nbconvert==7.16.3 (from -r requirements.txt (line 38))\n",
      "  Downloading nbconvert-7.16.3-py3-none-any.whl.metadata (8.2 kB)\n",
      "Requirement already satisfied: nbformat==5.10.4 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 39)) (5.10.4)\n",
      "Collecting networkx==3.2.1 (from -r requirements.txt (line 40))\n",
      "  Downloading networkx-3.2.1-py3-none-any.whl.metadata (5.2 kB)\n",
      "Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 41)) (1.26.4)\n",
      "Collecting nvidia-cublas-cu12==12.1.3.1 (from -r requirements.txt (line 42))\n",
      "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from -r requirements.txt (line 43))\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from -r requirements.txt (line 44))\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from -r requirements.txt (line 45))\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cudnn-cu12==8.9.2.26 (from -r requirements.txt (line 46))\n",
      "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cufft-cu12==11.0.2.54 (from -r requirements.txt (line 47))\n",
      "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.2.106 (from -r requirements.txt (line 48))\n",
      "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.4.5.107 (from -r requirements.txt (line 49))\n",
      "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.1.0.106 (from -r requirements.txt (line 50))\n",
      "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-nccl-cu12==2.19.3 (from -r requirements.txt (line 51))\n",
      "  Downloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-nvjitlink-cu12==12.4.127 (from -r requirements.txt (line 52))\n",
      "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-nvtx-cu12==12.1.105 (from -r requirements.txt (line 53))\n",
      "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting opencv-python==4.9.0.80 (from -r requirements.txt (line 54))\n",
      "  Downloading opencv_python-4.9.0.80-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
      "Collecting packaging==24.0 (from -r requirements.txt (line 55))\n",
      "  Downloading packaging-24.0-py3-none-any.whl.metadata (3.2 kB)\n",
      "Requirement already satisfied: pandocfilters==1.5.1 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 56)) (1.5.1)\n",
      "Requirement already satisfied: parso==0.8.4 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 57)) (0.8.4)\n",
      "Requirement already satisfied: pexpect==4.9.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 58)) (4.9.0)\n",
      "Requirement already satisfied: pickleshare==0.7.5 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 59)) (0.7.5)\n",
      "Collecting pillow==10.3.0 (from -r requirements.txt (line 60))\n",
      "  Downloading pillow-10.3.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (9.2 kB)\n",
      "Collecting pipreqs==0.5.0 (from -r requirements.txt (line 61))\n",
      "  Downloading pipreqs-0.5.0-py3-none-any.whl.metadata (7.9 kB)\n",
      "Collecting platformdirs==4.2.0 (from -r requirements.txt (line 62))\n",
      "  Downloading platformdirs-4.2.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting prompt-toolkit==3.0.43 (from -r requirements.txt (line 63))\n",
      "  Downloading prompt_toolkit-3.0.43-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting psutil==5.9.8 (from -r requirements.txt (line 64))\n",
      "  Downloading psutil-5.9.8-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (21 kB)\n",
      "Requirement already satisfied: ptyprocess==0.7.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 65)) (0.7.0)\n",
      "Collecting pure-eval==0.2.2 (from -r requirements.txt (line 66))\n",
      "  Downloading pure_eval-0.2.2-py3-none-any.whl.metadata (6.2 kB)\n",
      "Collecting Pygments==2.17.2 (from -r requirements.txt (line 67))\n",
      "  Downloading pygments-2.17.2-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: python-dateutil==2.9.0.post0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 68)) (2.9.0.post0)\n",
      "Collecting PyYAML==6.0.1 (from -r requirements.txt (line 69))\n",
      "  Downloading PyYAML-6.0.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.1 kB)\n",
      "Collecting pyzmq==25.1.2 (from -r requirements.txt (line 70))\n",
      "  Downloading pyzmq-25.1.2-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (4.9 kB)\n",
      "Collecting referencing==0.34.0 (from -r requirements.txt (line 71))\n",
      "  Downloading referencing-0.34.0-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting regex==2023.12.25 (from -r requirements.txt (line 72))\n",
      "  Downloading regex-2023.12.25-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.9/40.9 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting requests==2.31.0 (from -r requirements.txt (line 73))\n",
      "  Downloading requests-2.31.0-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting rpds-py==0.18.0 (from -r requirements.txt (line 74))\n",
      "  Downloading rpds_py-0.18.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
      "Collecting safetensors==0.4.2 (from -r requirements.txt (line 75))\n",
      "  Downloading safetensors-0.4.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Collecting six==1.16.0 (from -r requirements.txt (line 76))\n",
      "  Downloading six-1.16.0-py2.py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting soupsieve==2.5 (from -r requirements.txt (line 77))\n",
      "  Downloading soupsieve-2.5-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting stack-data==0.6.3 (from -r requirements.txt (line 78))\n",
      "  Downloading stack_data-0.6.3-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting sympy==1.12 (from -r requirements.txt (line 79))\n",
      "  Downloading sympy-1.12-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting tinycss2==1.2.1 (from -r requirements.txt (line 80))\n",
      "  Downloading tinycss2-1.2.1-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting tokenizers==0.15.2 (from -r requirements.txt (line 81))\n",
      "  Downloading tokenizers-0.15.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Collecting torch==2.2.2 (from -r requirements.txt (line 82))\n",
      "  Downloading torch-2.2.2-cp311-cp311-manylinux1_x86_64.whl.metadata (25 kB)\n",
      "Collecting torchvision==0.17.2 (from -r requirements.txt (line 83))\n",
      "  Downloading torchvision-0.17.2-cp311-cp311-manylinux1_x86_64.whl.metadata (6.6 kB)\n",
      "Collecting tornado==6.4 (from -r requirements.txt (line 84))\n",
      "  Downloading tornado-6.4-cp38-abi3-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.5 kB)\n",
      "Collecting tqdm==4.66.2 (from -r requirements.txt (line 85))\n",
      "  Downloading tqdm-4.66.2-py3-none-any.whl.metadata (57 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting traitlets==5.14.2 (from -r requirements.txt (line 86))\n",
      "  Downloading traitlets-5.14.2-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting transformers==4.39.3 (from -r requirements.txt (line 87))\n",
      "  Downloading transformers-4.39.3-py3-none-any.whl.metadata (134 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting triton==2.2.0 (from -r requirements.txt (line 88))\n",
      "  Downloading triton-2.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\n",
      "Collecting typing_extensions==4.11.0rc1 (from -r requirements.txt (line 89))\n",
      "  Downloading typing_extensions-4.11.0rc1-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting urllib3==2.2.1 (from -r requirements.txt (line 90))\n",
      "  Downloading urllib3-2.2.1-py3-none-any.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: wcwidth==0.2.13 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 91)) (0.2.13)\n",
      "Requirement already satisfied: webencodings==0.5.1 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 92)) (0.5.1)\n",
      "Collecting widgetsnbextension==4.0.10 (from -r requirements.txt (line 93))\n",
      "  Downloading widgetsnbextension-4.0.10-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting xformers==0.0.25.post1 (from -r requirements.txt (line 94))\n",
      "  Downloading xformers-0.0.25.post1-cp311-cp311-manylinux2014_x86_64.whl.metadata (1.0 kB)\n",
      "Collecting yarg==0.1.9 (from -r requirements.txt (line 95))\n",
      "  Downloading yarg-0.1.9-py2.py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting zipp==3.18.1 (from -r requirements.txt (line 96))\n",
      "  Downloading zipp-3.18.1-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting peft==0.9.0 (from -r requirements.txt (line 97))\n",
      "  Downloading peft-0.9.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.0->-r requirements.txt (line 41)) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.0->-r requirements.txt (line 41)) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.0->-r requirements.txt (line 41)) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.0->-r requirements.txt (line 41)) (2025.1.0)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.0->-r requirements.txt (line 41)) (2022.1.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.0->-r requirements.txt (line 41)) (2.4.1)\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.23.0->-r requirements.txt (line 41)) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.23.0->-r requirements.txt (line 41)) (2022.1.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.23.0->-r requirements.txt (line 41)) (1.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.23.0->-r requirements.txt (line 41)) (2024.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.23.0->-r requirements.txt (line 41)) (2024.2.0)\n",
      "Downloading accelerate-0.29.1-py3-none-any.whl (297 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m297.3/297.3 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading asttokens-2.4.1-py2.py3-none-any.whl (27 kB)\n",
      "Downloading attrs-23.2.0-py3-none-any.whl (60 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading beautifulsoup4-4.12.3-py3-none-any.whl (147 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.9/147.9 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading bleach-6.1.0-py3-none-any.whl (162 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m162.8/162.8 kB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading certifi-2024.2.2-py3-none-any.whl (163 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m163.8/163.8 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading charset_normalizer-3.3.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (140 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.3/140.3 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading decorator-5.1.1-py3-none-any.whl (9.1 kB)\n",
      "Downloading diffusers-0.27.2-py3-none-any.whl (2.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m48.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading einops-0.7.0-py3-none-any.whl (44 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.6/44.6 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading exceptiongroup-1.2.0-py3-none-any.whl (16 kB)\n",
      "Downloading executing-2.0.1-py2.py3-none-any.whl (24 kB)\n",
      "Downloading fastjsonschema-2.19.1-py3-none-any.whl (23 kB)\n",
      "Downloading filelock-3.13.3-py3-none-any.whl (11 kB)\n",
      "Downloading fsspec-2024.3.1-py3-none-any.whl (171 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m172.0/172.0 kB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading huggingface_hub-0.23.1-py3-none-any.whl (401 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m401.3/401.3 kB\u001b[0m \u001b[31m28.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading idna-3.6-py3-none-any.whl (61 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.6/61.6 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading importlib_metadata-7.1.0-py3-none-any.whl (24 kB)\n",
      "Downloading ipython-8.12.3-py3-none-any.whl (798 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m798.3/798.3 kB\u001b[0m \u001b[31m44.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading ipywidgets-8.1.2-py3-none-any.whl (139 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.4/139.4 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading jedi-0.19.1-py2.py3-none-any.whl (1.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m61.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading Jinja2-3.1.3-py3-none-any.whl (133 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.2/133.2 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading jsonschema-4.21.1-py3-none-any.whl (85 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.5/85.5 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading jsonschema_specifications-2023.12.1-py3-none-any.whl (18 kB)\n",
      "Downloading jupyter_client-8.6.1-py3-none-any.whl (105 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.9/105.9 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading jupyterlab_widgets-3.0.10-py3-none-any.whl (215 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m215.0/215.0 kB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading MarkupSafe-2.1.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (28 kB)\n",
      "Downloading matplotlib_inline-0.1.6-py3-none-any.whl (9.4 kB)\n",
      "Downloading mistune-3.0.2-py3-none-any.whl (47 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.0/48.0 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nbclient-0.10.0-py3-none-any.whl (25 kB)\n",
      "Downloading nbconvert-7.16.3-py3-none-any.whl (257 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m257.4/257.4 kB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading networkx-3.2.1-py3-none-any.whl (1.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m67.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m80.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m63.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m47.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m31.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m75.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading opencv_python-4.9.0.80-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (62.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.2/62.2 MB\u001b[0m \u001b[31m28.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading packaging-24.0-py3-none-any.whl (53 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.5/53.5 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pillow-10.3.0-cp311-cp311-manylinux_2_28_x86_64.whl (4.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m95.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pipreqs-0.5.0-py3-none-any.whl (33 kB)\n",
      "Downloading platformdirs-4.2.0-py3-none-any.whl (17 kB)\n",
      "Downloading prompt_toolkit-3.0.43-py3-none-any.whl (386 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m386.1/386.1 kB\u001b[0m \u001b[31m29.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading psutil-5.9.8-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (288 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m288.2/288.2 kB\u001b[0m \u001b[31m19.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pure_eval-0.2.2-py3-none-any.whl (11 kB)\n",
      "Downloading pygments-2.17.2-py3-none-any.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m59.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading PyYAML-6.0.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (757 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m757.7/757.7 kB\u001b[0m \u001b[31m48.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pyzmq-25.1.2-cp311-cp311-manylinux_2_28_x86_64.whl (1.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m49.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading referencing-0.34.0-py3-none-any.whl (26 kB)\n",
      "Downloading regex-2023.12.25-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (785 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m785.1/785.1 kB\u001b[0m \u001b[31m44.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading requests-2.31.0-py3-none-any.whl (62 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.6/62.6 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading rpds_py-0.18.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m53.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading safetensors-0.4.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m63.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading six-1.16.0-py2.py3-none-any.whl (11 kB)\n",
      "Downloading soupsieve-2.5-py3-none-any.whl (36 kB)\n",
      "Downloading stack_data-0.6.3-py3-none-any.whl (24 kB)\n",
      "Downloading sympy-1.12-py3-none-any.whl (5.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.7/5.7 MB\u001b[0m \u001b[31m104.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading tinycss2-1.2.1-py3-none-any.whl (21 kB)\n",
      "Downloading tokenizers-0.15.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m92.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading torch-2.2.2-cp311-cp311-manylinux1_x86_64.whl (755.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m755.6/755.6 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading torchvision-0.17.2-cp311-cp311-manylinux1_x86_64.whl (6.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading tornado-6.4-cp38-abi3-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (435 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m435.4/435.4 kB\u001b[0m \u001b[31m517.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading tqdm-4.66.2-py3-none-any.whl (78 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.3/78.3 kB\u001b[0m \u001b[31m116.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading traitlets-5.14.2-py3-none-any.whl (85 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.4/85.4 kB\u001b[0m \u001b[31m96.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading transformers-4.39.3-py3-none-any.whl (8.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.8/8.8 MB\u001b[0m \u001b[31m28.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading triton-2.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (167.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.9/167.9 MB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading typing_extensions-4.11.0rc1-py3-none-any.whl (34 kB)\n",
      "Downloading urllib3-2.2.1-py3-none-any.whl (121 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.1/121.1 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading widgetsnbextension-4.0.10-py3-none-any.whl (2.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m73.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading xformers-0.0.25.post1-cp311-cp311-manylinux2014_x86_64.whl (222.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m222.6/222.6 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading yarg-0.1.9-py2.py3-none-any.whl (19 kB)\n",
      "Downloading zipp-3.18.1-py3-none-any.whl (8.2 kB)\n",
      "Downloading peft-0.9.0-py3-none-any.whl (190 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.9/190.9 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: docopt\n",
      "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13706 sha256=9e957b53087a58291713ebdf8e197fbe1dd3fb5274c6e56ee5796471e9e7dc67\n",
      "  Stored in directory: /root/.cache/pip/wheels/1a/b0/8c/4b75c4116c31f83c8f9f047231251e13cc74481cca4a78a9ce\n",
      "Successfully built docopt\n",
      "Installing collected packages: pure-eval, fastjsonschema, docopt, zipp, widgetsnbextension, urllib3, typing_extensions, traitlets, tqdm, tornado, tinycss2, sympy, soupsieve, six, safetensors, rpds-py, regex, pyzmq, PyYAML, Pygments, psutil, prompt-toolkit, platformdirs, pillow, packaging, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, networkx, mistune, MarkupSafe, jupyterlab_widgets, jedi, idna, fsspec, filelock, executing, exceptiongroup, einops, decorator, charset-normalizer, certifi, attrs, triton, requests, referencing, nvidia-cusparse-cu12, nvidia-cudnn-cu12, matplotlib-inline, Jinja2, importlib_metadata, bleach, beautifulsoup4, asttokens, yarg, stack-data, nvidia-cusolver-cu12, jupyter_client, jsonschema-specifications, huggingface-hub, torch, tokenizers, jsonschema, ipython, ipywidgets, nbclient, nbconvert, pipreqs, transformers, accelerate, xformers, torchvision, peft, opencv-python, diffusers\n",
      "  Attempting uninstall: fastjsonschema\n",
      "    Found existing installation: fastjsonschema 2.21.1\n",
      "    Uninstalling fastjsonschema-2.21.1:\n",
      "      Successfully uninstalled fastjsonschema-2.21.1\n",
      "  Attempting uninstall: zipp\n",
      "    Found existing installation: zipp 3.21.0\n",
      "    Uninstalling zipp-3.21.0:\n",
      "      Successfully uninstalled zipp-3.21.0\n",
      "  Attempting uninstall: widgetsnbextension\n",
      "    Found existing installation: widgetsnbextension 4.0.13\n",
      "    Uninstalling widgetsnbextension-4.0.13:\n",
      "      Successfully uninstalled widgetsnbextension-4.0.13\n",
      "  Attempting uninstall: urllib3\n",
      "    Found existing installation: urllib3 2.3.0\n",
      "    Uninstalling urllib3-2.3.0:\n",
      "      Successfully uninstalled urllib3-2.3.0\n",
      "  Attempting uninstall: typing_extensions\n",
      "    Found existing installation: typing_extensions 4.13.1\n",
      "    Uninstalling typing_extensions-4.13.1:\n",
      "      Successfully uninstalled typing_extensions-4.13.1\n",
      "  Attempting uninstall: traitlets\n",
      "    Found existing installation: traitlets 5.7.1\n",
      "    Uninstalling traitlets-5.7.1:\n",
      "      Successfully uninstalled traitlets-5.7.1\n",
      "  Attempting uninstall: tqdm\n",
      "    Found existing installation: tqdm 4.67.1\n",
      "    Uninstalling tqdm-4.67.1:\n",
      "      Successfully uninstalled tqdm-4.67.1\n",
      "  Attempting uninstall: tornado\n",
      "    Found existing installation: tornado 6.4.2\n",
      "    Uninstalling tornado-6.4.2:\n",
      "      Successfully uninstalled tornado-6.4.2\n",
      "  Attempting uninstall: tinycss2\n",
      "    Found existing installation: tinycss2 1.4.0\n",
      "    Uninstalling tinycss2-1.4.0:\n",
      "      Successfully uninstalled tinycss2-1.4.0\n",
      "  Attempting uninstall: sympy\n",
      "    Found existing installation: sympy 1.13.1\n",
      "    Uninstalling sympy-1.13.1:\n",
      "      Successfully uninstalled sympy-1.13.1\n",
      "  Attempting uninstall: soupsieve\n",
      "    Found existing installation: soupsieve 2.6\n",
      "    Uninstalling soupsieve-2.6:\n",
      "      Successfully uninstalled soupsieve-2.6\n",
      "  Attempting uninstall: six\n",
      "    Found existing installation: six 1.17.0\n",
      "    Uninstalling six-1.17.0:\n",
      "      Successfully uninstalled six-1.17.0\n",
      "  Attempting uninstall: safetensors\n",
      "    Found existing installation: safetensors 0.5.2\n",
      "    Uninstalling safetensors-0.5.2:\n",
      "      Successfully uninstalled safetensors-0.5.2\n",
      "  Attempting uninstall: rpds-py\n",
      "    Found existing installation: rpds-py 0.22.3\n",
      "    Uninstalling rpds-py-0.22.3:\n",
      "      Successfully uninstalled rpds-py-0.22.3\n",
      "  Attempting uninstall: regex\n",
      "    Found existing installation: regex 2024.11.6\n",
      "    Uninstalling regex-2024.11.6:\n",
      "      Successfully uninstalled regex-2024.11.6\n",
      "  Attempting uninstall: pyzmq\n",
      "    Found existing installation: pyzmq 24.0.1\n",
      "    Uninstalling pyzmq-24.0.1:\n",
      "      Successfully uninstalled pyzmq-24.0.1\n",
      "  Attempting uninstall: PyYAML\n",
      "    Found existing installation: PyYAML 6.0.2\n",
      "    Uninstalling PyYAML-6.0.2:\n",
      "      Successfully uninstalled PyYAML-6.0.2\n",
      "  Attempting uninstall: Pygments\n",
      "    Found existing installation: Pygments 2.19.1\n",
      "    Uninstalling Pygments-2.19.1:\n",
      "      Successfully uninstalled Pygments-2.19.1\n",
      "  Attempting uninstall: psutil\n",
      "    Found existing installation: psutil 7.0.0\n",
      "    Uninstalling psutil-7.0.0:\n",
      "      Successfully uninstalled psutil-7.0.0\n",
      "  Attempting uninstall: prompt-toolkit\n",
      "    Found existing installation: prompt_toolkit 3.0.50\n",
      "    Uninstalling prompt_toolkit-3.0.50:\n",
      "      Successfully uninstalled prompt_toolkit-3.0.50\n",
      "  Attempting uninstall: platformdirs\n",
      "    Found existing installation: platformdirs 4.3.7\n",
      "    Uninstalling platformdirs-4.3.7:\n",
      "      Successfully uninstalled platformdirs-4.3.7\n",
      "  Attempting uninstall: pillow\n",
      "    Found existing installation: pillow 11.1.0\n",
      "    Uninstalling pillow-11.1.0:\n",
      "      Successfully uninstalled pillow-11.1.0\n",
      "  Attempting uninstall: packaging\n",
      "    Found existing installation: packaging 24.2\n",
      "    Uninstalling packaging-24.2:\n",
      "      Successfully uninstalled packaging-24.2\n",
      "  Attempting uninstall: nvidia-nvtx-cu12\n",
      "    Found existing installation: nvidia-nvtx-cu12 12.4.127\n",
      "    Uninstalling nvidia-nvtx-cu12-12.4.127:\n",
      "      Successfully uninstalled nvidia-nvtx-cu12-12.4.127\n",
      "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
      "    Found existing installation: nvidia-nvjitlink-cu12 12.8.93\n",
      "    Uninstalling nvidia-nvjitlink-cu12-12.8.93:\n",
      "      Successfully uninstalled nvidia-nvjitlink-cu12-12.8.93\n",
      "  Attempting uninstall: nvidia-nccl-cu12\n",
      "    Found existing installation: nvidia-nccl-cu12 2.21.5\n",
      "    Uninstalling nvidia-nccl-cu12-2.21.5:\n",
      "      Successfully uninstalled nvidia-nccl-cu12-2.21.5\n",
      "  Attempting uninstall: nvidia-curand-cu12\n",
      "    Found existing installation: nvidia-curand-cu12 10.3.9.90\n",
      "    Uninstalling nvidia-curand-cu12-10.3.9.90:\n",
      "      Successfully uninstalled nvidia-curand-cu12-10.3.9.90\n",
      "  Attempting uninstall: nvidia-cufft-cu12\n",
      "    Found existing installation: nvidia-cufft-cu12 11.3.3.83\n",
      "    Uninstalling nvidia-cufft-cu12-11.3.3.83:\n",
      "      Successfully uninstalled nvidia-cufft-cu12-11.3.3.83\n",
      "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
      "    Found existing installation: nvidia-cuda-runtime-cu12 12.4.127\n",
      "    Uninstalling nvidia-cuda-runtime-cu12-12.4.127:\n",
      "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.4.127\n",
      "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
      "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.4.127\n",
      "    Uninstalling nvidia-cuda-nvrtc-cu12-12.4.127:\n",
      "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.4.127\n",
      "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
      "    Found existing installation: nvidia-cuda-cupti-cu12 12.4.127\n",
      "    Uninstalling nvidia-cuda-cupti-cu12-12.4.127:\n",
      "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.4.127\n",
      "  Attempting uninstall: nvidia-cublas-cu12\n",
      "    Found existing installation: nvidia-cublas-cu12 12.8.4.1\n",
      "    Uninstalling nvidia-cublas-cu12-12.8.4.1:\n",
      "      Successfully uninstalled nvidia-cublas-cu12-12.8.4.1\n",
      "  Attempting uninstall: networkx\n",
      "    Found existing installation: networkx 3.4.2\n",
      "    Uninstalling networkx-3.4.2:\n",
      "      Successfully uninstalled networkx-3.4.2\n",
      "  Attempting uninstall: mistune\n",
      "    Found existing installation: mistune 0.8.4\n",
      "    Uninstalling mistune-0.8.4:\n",
      "      Successfully uninstalled mistune-0.8.4\n",
      "  Attempting uninstall: MarkupSafe\n",
      "    Found existing installation: MarkupSafe 3.0.2\n",
      "    Uninstalling MarkupSafe-3.0.2:\n",
      "      Successfully uninstalled MarkupSafe-3.0.2\n",
      "  Attempting uninstall: jupyterlab_widgets\n",
      "    Found existing installation: jupyterlab_widgets 3.0.13\n",
      "    Uninstalling jupyterlab_widgets-3.0.13:\n",
      "      Successfully uninstalled jupyterlab_widgets-3.0.13\n",
      "  Attempting uninstall: jedi\n",
      "    Found existing installation: jedi 0.19.2\n",
      "    Uninstalling jedi-0.19.2:\n",
      "      Successfully uninstalled jedi-0.19.2\n",
      "  Attempting uninstall: idna\n",
      "    Found existing installation: idna 3.10\n",
      "    Uninstalling idna-3.10:\n",
      "      Successfully uninstalled idna-3.10\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2025.3.2\n",
      "    Uninstalling fsspec-2025.3.2:\n",
      "      Successfully uninstalled fsspec-2025.3.2\n",
      "  Attempting uninstall: filelock\n",
      "    Found existing installation: filelock 3.18.0\n",
      "    Uninstalling filelock-3.18.0:\n",
      "      Successfully uninstalled filelock-3.18.0\n",
      "  Attempting uninstall: einops\n",
      "    Found existing installation: einops 0.8.1\n",
      "    Uninstalling einops-0.8.1:\n",
      "      Successfully uninstalled einops-0.8.1\n",
      "  Attempting uninstall: decorator\n",
      "    Found existing installation: decorator 4.4.2\n",
      "    Uninstalling decorator-4.4.2:\n",
      "      Successfully uninstalled decorator-4.4.2\n",
      "  Attempting uninstall: charset-normalizer\n",
      "    Found existing installation: charset-normalizer 3.4.1\n",
      "    Uninstalling charset-normalizer-3.4.1:\n",
      "      Successfully uninstalled charset-normalizer-3.4.1\n",
      "  Attempting uninstall: certifi\n",
      "    Found existing installation: certifi 2025.1.31\n",
      "    Uninstalling certifi-2025.1.31:\n",
      "      Successfully uninstalled certifi-2025.1.31\n",
      "  Attempting uninstall: attrs\n",
      "    Found existing installation: attrs 25.3.0\n",
      "    Uninstalling attrs-25.3.0:\n",
      "      Successfully uninstalled attrs-25.3.0\n",
      "  Attempting uninstall: triton\n",
      "    Found existing installation: triton 3.1.0\n",
      "    Uninstalling triton-3.1.0:\n",
      "      Successfully uninstalled triton-3.1.0\n",
      "  Attempting uninstall: requests\n",
      "    Found existing installation: requests 2.32.3\n",
      "    Uninstalling requests-2.32.3:\n",
      "      Successfully uninstalled requests-2.32.3\n",
      "  Attempting uninstall: referencing\n",
      "    Found existing installation: referencing 0.36.2\n",
      "    Uninstalling referencing-0.36.2:\n",
      "      Successfully uninstalled referencing-0.36.2\n",
      "  Attempting uninstall: nvidia-cusparse-cu12\n",
      "    Found existing installation: nvidia-cusparse-cu12 12.5.8.93\n",
      "    Uninstalling nvidia-cusparse-cu12-12.5.8.93:\n",
      "      Successfully uninstalled nvidia-cusparse-cu12-12.5.8.93\n",
      "  Attempting uninstall: nvidia-cudnn-cu12\n",
      "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
      "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
      "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
      "  Attempting uninstall: matplotlib-inline\n",
      "    Found existing installation: matplotlib-inline 0.1.7\n",
      "    Uninstalling matplotlib-inline-0.1.7:\n",
      "      Successfully uninstalled matplotlib-inline-0.1.7\n",
      "  Attempting uninstall: Jinja2\n",
      "    Found existing installation: Jinja2 3.1.6\n",
      "    Uninstalling Jinja2-3.1.6:\n",
      "      Successfully uninstalled Jinja2-3.1.6\n",
      "  Attempting uninstall: importlib_metadata\n",
      "    Found existing installation: importlib_metadata 8.6.1\n",
      "    Uninstalling importlib_metadata-8.6.1:\n",
      "      Successfully uninstalled importlib_metadata-8.6.1\n",
      "  Attempting uninstall: bleach\n",
      "    Found existing installation: bleach 6.2.0\n",
      "    Uninstalling bleach-6.2.0:\n",
      "      Successfully uninstalled bleach-6.2.0\n",
      "  Attempting uninstall: beautifulsoup4\n",
      "    Found existing installation: beautifulsoup4 4.13.3\n",
      "    Uninstalling beautifulsoup4-4.13.3:\n",
      "      Successfully uninstalled beautifulsoup4-4.13.3\n",
      "  Attempting uninstall: asttokens\n",
      "    Found existing installation: asttokens 3.0.0\n",
      "    Uninstalling asttokens-3.0.0:\n",
      "      Successfully uninstalled asttokens-3.0.0\n",
      "  Attempting uninstall: nvidia-cusolver-cu12\n",
      "    Found existing installation: nvidia-cusolver-cu12 11.7.3.90\n",
      "    Uninstalling nvidia-cusolver-cu12-11.7.3.90:\n",
      "      Successfully uninstalled nvidia-cusolver-cu12-11.7.3.90\n",
      "  Attempting uninstall: jupyter_client\n",
      "    Found existing installation: jupyter_client 8.6.3\n",
      "    Uninstalling jupyter_client-8.6.3:\n",
      "      Successfully uninstalled jupyter_client-8.6.3\n",
      "  Attempting uninstall: jsonschema-specifications\n",
      "    Found existing installation: jsonschema-specifications 2024.10.1\n",
      "    Uninstalling jsonschema-specifications-2024.10.1:\n",
      "      Successfully uninstalled jsonschema-specifications-2024.10.1\n",
      "  Attempting uninstall: huggingface-hub\n",
      "    Found existing installation: huggingface-hub 0.30.2\n",
      "    Uninstalling huggingface-hub-0.30.2:\n",
      "      Successfully uninstalled huggingface-hub-0.30.2\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 2.5.1+cu124\n",
      "    Uninstalling torch-2.5.1+cu124:\n",
      "      Successfully uninstalled torch-2.5.1+cu124\n",
      "  Attempting uninstall: tokenizers\n",
      "    Found existing installation: tokenizers 0.21.0\n",
      "    Uninstalling tokenizers-0.21.0:\n",
      "      Successfully uninstalled tokenizers-0.21.0\n",
      "  Attempting uninstall: jsonschema\n",
      "    Found existing installation: jsonschema 4.23.0\n",
      "    Uninstalling jsonschema-4.23.0:\n",
      "      Successfully uninstalled jsonschema-4.23.0\n",
      "  Attempting uninstall: ipython\n",
      "    Found existing installation: ipython 7.34.0\n",
      "    Uninstalling ipython-7.34.0:\n",
      "      Successfully uninstalled ipython-7.34.0\n",
      "  Attempting uninstall: ipywidgets\n",
      "    Found existing installation: ipywidgets 8.1.5\n",
      "    Uninstalling ipywidgets-8.1.5:\n",
      "      Successfully uninstalled ipywidgets-8.1.5\n",
      "  Attempting uninstall: nbclient\n",
      "    Found existing installation: nbclient 0.5.13\n",
      "    Uninstalling nbclient-0.5.13:\n",
      "      Successfully uninstalled nbclient-0.5.13\n",
      "  Attempting uninstall: nbconvert\n",
      "    Found existing installation: nbconvert 6.4.5\n",
      "    Uninstalling nbconvert-6.4.5:\n",
      "      Successfully uninstalled nbconvert-6.4.5\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.51.1\n",
      "    Uninstalling transformers-4.51.1:\n",
      "      Successfully uninstalled transformers-4.51.1\n",
      "  Attempting uninstall: accelerate\n",
      "    Found existing installation: accelerate 1.3.0\n",
      "    Uninstalling accelerate-1.3.0:\n",
      "      Successfully uninstalled accelerate-1.3.0\n",
      "  Attempting uninstall: torchvision\n",
      "    Found existing installation: torchvision 0.20.1+cu124\n",
      "    Uninstalling torchvision-0.20.1+cu124:\n",
      "      Successfully uninstalled torchvision-0.20.1+cu124\n",
      "  Attempting uninstall: peft\n",
      "    Found existing installation: peft 0.14.0\n",
      "    Uninstalling peft-0.14.0:\n",
      "      Successfully uninstalled peft-0.14.0\n",
      "  Attempting uninstall: opencv-python\n",
      "    Found existing installation: opencv-python 4.11.0.86\n",
      "    Uninstalling opencv-python-4.11.0.86:\n",
      "      Successfully uninstalled opencv-python-4.11.0.86\n",
      "  Attempting uninstall: diffusers\n",
      "    Found existing installation: diffusers 0.32.2\n",
      "    Uninstalling diffusers-0.32.2:\n",
      "      Successfully uninstalled diffusers-0.32.2\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "typing-inspection 0.4.0 requires typing-extensions>=4.12.0, but you have typing-extensions 4.11.0rc1 which is incompatible.\n",
      "pydantic 2.11.3 requires typing-extensions>=4.12.2, but you have typing-extensions 4.11.0rc1 which is incompatible.\n",
      "sigstore 3.6.1 requires rich~=13.0, but you have rich 14.0.0 which is incompatible.\n",
      "datasets 3.5.0 requires huggingface-hub>=0.24.0, but you have huggingface-hub 0.23.1 which is incompatible.\n",
      "datasets 3.5.0 requires requests>=2.32.2, but you have requests 2.31.0 which is incompatible.\n",
      "datasets 3.5.0 requires tqdm>=4.66.3, but you have tqdm 4.66.2 which is incompatible.\n",
      "featuretools 1.31.0 requires tqdm>=4.66.3, but you have tqdm 4.66.2 which is incompatible.\n",
      "alembic 1.15.2 requires typing-extensions>=4.12, but you have typing-extensions 4.11.0rc1 which is incompatible.\n",
      "nilearn 0.11.1 requires scikit-learn>=1.4.0, but you have scikit-learn 1.2.2 which is incompatible.\n",
      "preprocessing 0.1.13 requires nltk==3.2.4, but you have nltk 3.9.1 which is incompatible.\n",
      "google-colab 1.0.0 requires ipython==7.34.0, but you have ipython 8.12.3 which is incompatible.\n",
      "google-colab 1.0.0 requires notebook==6.5.5, but you have notebook 6.5.4 which is incompatible.\n",
      "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.2.3 which is incompatible.\n",
      "google-colab 1.0.0 requires requests==2.32.3, but you have requests 2.31.0 which is incompatible.\n",
      "google-colab 1.0.0 requires tornado==6.4.2, but you have tornado 6.4 which is incompatible.\n",
      "dopamine-rl 4.1.2 requires gymnasium>=1.0.0, but you have gymnasium 0.29.0 which is incompatible.\n",
      "openai 1.61.1 requires typing-extensions<5,>=4.11, but you have typing-extensions 4.11.0rc1 which is incompatible.\n",
      "sentence-transformers 3.4.1 requires transformers<5.0.0,>=4.41.0, but you have transformers 4.39.3 which is incompatible.\n",
      "moviepy 1.0.3 requires decorator<5.0,>=4.0.2, but you have decorator 5.1.1 which is incompatible.\n",
      "google-spark-connect 0.5.2 requires google-api-core>=2.19.1, but you have google-api-core 1.34.1 which is incompatible.\n",
      "pandas-gbq 0.26.1 requires google-api-core<3.0.0dev,>=2.10.2, but you have google-api-core 1.34.1 which is incompatible.\n",
      "gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.3.1 which is incompatible.\n",
      "bigframes 1.36.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\n",
      "pydrive2 1.21.3 requires cryptography<44, but you have cryptography 44.0.2 which is incompatible.\n",
      "pydrive2 1.21.3 requires pyOpenSSL<=24.2.1,>=19.1.0, but you have pyopenssl 25.0.0 which is incompatible.\n",
      "pytensor 2.27.1 requires filelock>=3.15, but you have filelock 3.13.3 which is incompatible.\n",
      "ibis-framework 9.2.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\n",
      "ibis-framework 9.2.0 requires toolz<1,>=0.11, but you have toolz 1.0.0 which is incompatible.\n",
      "plotnine 0.14.5 requires matplotlib>=3.8.0, but you have matplotlib 3.7.5 which is incompatible.\n",
      "torchaudio 2.5.1+cu124 requires torch==2.5.1, but you have torch 2.2.2 which is incompatible.\n",
      "pylibcugraph-cu12 24.12.0 requires pylibraft-cu12==24.12.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\n",
      "pylibcugraph-cu12 24.12.0 requires rmm-cu12==24.12.*, but you have rmm-cu12 25.2.0 which is incompatible.\n",
      "google-cloud-bigtable 2.28.1 requires google-api-core[grpc]<3.0.0dev,>=2.16.0, but you have google-api-core 1.34.1 which is incompatible.\n",
      "mlxtend 0.23.4 requires scikit-learn>=1.3.1, but you have scikit-learn 1.2.2 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed Jinja2-3.1.3 MarkupSafe-2.1.5 PyYAML-6.0.1 Pygments-2.17.2 accelerate-0.29.1 asttokens-2.4.1 attrs-23.2.0 beautifulsoup4-4.12.3 bleach-6.1.0 certifi-2024.2.2 charset-normalizer-3.3.2 decorator-5.1.1 diffusers-0.27.2 docopt-0.6.2 einops-0.7.0 exceptiongroup-1.2.0 executing-2.0.1 fastjsonschema-2.19.1 filelock-3.13.3 fsspec-2024.3.1 huggingface-hub-0.23.1 idna-3.6 importlib_metadata-7.1.0 ipython-8.12.3 ipywidgets-8.1.2 jedi-0.19.1 jsonschema-4.21.1 jsonschema-specifications-2023.12.1 jupyter_client-8.6.1 jupyterlab_widgets-3.0.10 matplotlib-inline-0.1.6 mistune-3.0.2 nbclient-0.10.0 nbconvert-7.16.3 networkx-3.2.1 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.1.105 opencv-python-4.9.0.80 packaging-24.0 peft-0.9.0 pillow-10.3.0 pipreqs-0.5.0 platformdirs-4.2.0 prompt-toolkit-3.0.43 psutil-5.9.8 pure-eval-0.2.2 pyzmq-25.1.2 referencing-0.34.0 regex-2023.12.25 requests-2.31.0 rpds-py-0.18.0 safetensors-0.4.2 six-1.16.0 soupsieve-2.5 stack-data-0.6.3 sympy-1.12 tinycss2-1.2.1 tokenizers-0.15.2 torch-2.2.2 torchvision-0.17.2 tornado-6.4 tqdm-4.66.2 traitlets-5.14.2 transformers-4.39.3 triton-2.2.0 typing_extensions-4.11.0rc1 urllib3-2.2.1 widgetsnbextension-4.0.10 xformers-0.0.25.post1 yarg-0.1.9 zipp-3.18.1\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-03T21:29:46.621815Z",
     "iopub.status.busy": "2025-05-03T21:29:46.621488Z",
     "iopub.status.idle": "2025-05-03T21:29:46.629520Z",
     "shell.execute_reply": "2025-05-03T21:29:46.628833Z",
     "shell.execute_reply.started": "2025-05-03T21:29:46.621786Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting mllm.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile mllm.py\n",
    "import requests\n",
    "import json\n",
    "import os\n",
    "from transformers import AutoTokenizer\n",
    "import transformers\n",
    "import torch\n",
    "import re\n",
    "import torch\n",
    "from transformers import LlamaForCausalLM, LlamaTokenizer\n",
    "from openai import OpenAI\n",
    "\n",
    "\n",
    "\n",
    "def GPT4(prompt, key):\n",
    "    url = \"https://api.openai.com/v1/chat/completions\"\n",
    "    api_key = key\n",
    "\n",
    "    # Check if the template file exists\n",
    "    if not os.path.exists('template/template.txt'):\n",
    "        print(\"❌ Missing file: template/template.txt\")\n",
    "        return {}\n",
    "\n",
    "    with open('template/template.txt', 'r') as f:\n",
    "        template = f.readlines()\n",
    "\n",
    "    user_textprompt = f\"Caption:{prompt} \\n Let's think step by step:\"\n",
    "    textprompt = f\"{' '.join(template)} \\n {user_textprompt}\"\n",
    "\n",
    "    payload = json.dumps({\n",
    "        \"model\": \"gpt-4o\",  # You can also try gpt-4 or gpt-3.5-turbo\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": textprompt\n",
    "            }\n",
    "        ]\n",
    "    })\n",
    "\n",
    "    headers = {\n",
    "        'Accept': 'application/json',\n",
    "        'Authorization': f'Bearer {api_key}',\n",
    "        'User-Agent': 'Apifox/1.0.0 (https://apifox.com)',\n",
    "        'Content-Type': 'application/json'\n",
    "    }\n",
    "\n",
    "    print('🧠 Waiting for GPT-4 response...')\n",
    "    try:\n",
    "        response = requests.post(url, headers=headers, data=payload)\n",
    "        obj = response.json()\n",
    "\n",
    "        # Debug print full response if 'choices' is missing\n",
    "        if 'choices' not in obj:\n",
    "            print(\"❌ API response does not contain 'choices':\")\n",
    "            print(json.dumps(obj, indent=2))\n",
    "            return {}\n",
    "\n",
    "        text = obj['choices'][0]['message']['content']\n",
    "        print(\"✅ GPT-4 Response:\")\n",
    "        print(text)\n",
    "\n",
    "        return get_params_dict(text)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"🚨 Exception while calling GPT-4:\", str(e))\n",
    "        return {}\n",
    "\n",
    "\n",
    "def DeepSeekR1(prompt, key):\n",
    "    url = \"https://openrouter.ai/api/v1/chat/completions\"\n",
    "    api_key=key\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {api_key}\",\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"HTTP-Referer\": \"https://yourdomain.com\",  # Optional\n",
    "        \"X-Title\": \"RPG\"\n",
    "    }\n",
    "\n",
    "    with open('template/template.txt', 'r') as f:\n",
    "        template = f.readlines()\n",
    "\n",
    "    user_textprompt = f\"Caption:{prompt} \\n Let's think step by step:\"\n",
    "    textprompt = f\"{' '.join(template)} \\n {user_textprompt}\"\n",
    "\n",
    "    data = {\n",
    "        \"model\": \"deepseek/deepseek-r1:free\",  # ✅ Correct model ID\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": textprompt\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    print(\"🧠 Waiting for DeepSeekR1 response...\")\n",
    "    response = requests.post(url, headers=headers, data=json.dumps(data))\n",
    "\n",
    "    try:\n",
    "        obj = response.json()\n",
    "        if \"choices\" not in obj:\n",
    "            print(\"❌ No 'choices' in response:\", obj)\n",
    "            return None\n",
    "\n",
    "        text = obj['choices'][0]['message']['content']\n",
    "        print(\"✅ DeepSeekR1 response:\", text)\n",
    "        return get_params_dict(text)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"❌ Failed to parse response:\", e)\n",
    "        return None\n",
    "\n",
    "\n",
    "\n",
    "def local_llm(prompt,version,model_path=None):\n",
    "    if model_path==None:\n",
    "        model_id = \"Llama-2-13b-chat-hf\" \n",
    "    else:\n",
    "        model_id=model_path\n",
    "    print('Using model:',model_id)\n",
    "    tokenizer = LlamaTokenizer.from_pretrained(model_id)\n",
    "    model = LlamaForCausalLM.from_pretrained(model_id, load_in_8bit=False, device_map='auto', torch_dtype=torch.float16)\n",
    "    with open('template/template.txt', 'r') as f:\n",
    "        template=f.readlines()\n",
    "    user_textprompt=f\"Caption:{prompt} \\n Let's think step by step:\"\n",
    "    textprompt= f\"{' '.join(template)} \\n {user_textprompt}\"\n",
    "    model_input = tokenizer(textprompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        print('waiting for LLM response')\n",
    "        res = model.generate(**model_input, max_new_tokens=1024)[0]\n",
    "        output=tokenizer.decode(res, skip_special_tokens=True)\n",
    "        output = output.replace(textprompt,'')\n",
    "    return get_params_dict(output)\n",
    "\n",
    "\n",
    "\n",
    "def get_params_dict(output_text):\n",
    "    response = output_text\n",
    "\n",
    "    final_split_ratio = None\n",
    "    regional_prompt = None\n",
    "\n",
    "    # Match Final split ratio (flexible to colons, spaces, and newlines)\n",
    "    split_ratio_match = re.search(\n",
    "        r\"Final split ratio\\s*[:\\-]?\\s*\\n?\\s*([0-9.,;\\s]+)\", response, re.IGNORECASE\n",
    "    )\n",
    "    if split_ratio_match:\n",
    "        final_split_ratio = split_ratio_match.group(1).strip().replace(\" \", \"\")\n",
    "        print(\"✅ Final split ratio:\", final_split_ratio)\n",
    "    else:\n",
    "        print(\"❌ Final split ratio not found.\")\n",
    "\n",
    "    # Match Regional Prompt (flexible to colons, spaces, and newlines)\n",
    "    prompt_match = re.search(\n",
    "        r\"Regional Prompt\\s*[:\\-]?\\s*\\n?\\s*(.+)\", response, re.DOTALL | re.IGNORECASE\n",
    "    )\n",
    "    if prompt_match:\n",
    "        regional_prompt = prompt_match.group(1).strip()\n",
    "        print(\"✅ Regional Prompt:\", regional_prompt)\n",
    "    else:\n",
    "        print(\"❌ Regional Prompt not found.\")\n",
    "\n",
    "    # Final check\n",
    "    if final_split_ratio is None or regional_prompt is None:\n",
    "        return None\n",
    "\n",
    "    return {\n",
    "        \"Final split ratio\": final_split_ratio,\n",
    "        \"Regional Prompt\": regional_prompt\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-04T00:08:17.508393Z",
     "iopub.status.busy": "2025-05-04T00:08:17.508123Z",
     "iopub.status.idle": "2025-05-04T00:08:17.515144Z",
     "shell.execute_reply": "2025-05-04T00:08:17.514386Z",
     "shell.execute_reply.started": "2025-05-04T00:08:17.508369Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting RPG.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile RPG.py\n",
    "from RegionalDiffusion_base import RegionalDiffusionPipeline\n",
    "from RegionalDiffusion_xl import RegionalDiffusionXLPipeline\n",
    "from diffusers.schedulers import KarrasDiffusionSchedulers,DPMSolverMultistepScheduler\n",
    "from mllm import local_llm,GPT4,DeepSeekR1\n",
    "import torch\n",
    "# If you want to load ckpt, initialize with \".from_single_file\".\n",
    "# pipe = RegionalDiffusionXLPipeline.from_single_file(\"path to your ckpt\",torch_dtype=torch.float16, use_safetensors=True, variant=\"fp16\")\n",
    "# If you want to use diffusers, initialize with \".from_pretrained\".\n",
    "# pipe = RegionalDiffusionPipeline.from_pretrained(\"CompVis/stable-diffusion-v1-4\",torch_dtype=torch.float16, use_safetensors=True)\n",
    "from huggingface_hub import login\n",
    "\n",
    "# Paste your token here — ideally from Kaggle secrets (safer), or directly for now\n",
    "login(token=\"your Hugging Face token here\")\n",
    "pipe = RegionalDiffusionPipeline.from_pretrained(\"Nihirc/Prompt2MedImage\",torch_dtype=torch.float16, use_safetensors=True)\n",
    "# pipe = RegionalDiffusionXLPipeline.from_pretrained(\"Nihirc/Prompt2MedImage\",torch_dtype=torch.float16, use_safetensors=True)\n",
    "pipe.to(\"cuda\")\n",
    "pipe.scheduler = DPMSolverMultistepScheduler.from_config(pipe.scheduler.config,use_karras_sigmas=True)\n",
    "pipe.enable_xformers_memory_efficient_attention()\n",
    "## User input\n",
    "prompt= 'A 3-year-old child with visual difficulties. Axial FLAIR image show a supra-sellar lesion extending to the temporal lobes along the optic tracts (arrows) with moderate mass effect, compatible with optic glioma. FLAIR hyperintensity is also noted in the left mesencephalon from additional tumoral involvement.'\n",
    "para_dict = DeepSeekR1(prompt,key='your OpenRouter API key here')\n",
    "## MLLM based split generation results\n",
    "if para_dict is None:\n",
    "    raise ValueError(\"Model did not return a valid response. Check logs for details.\")\n",
    "\n",
    "split_ratio = para_dict['Final split ratio']\n",
    "regional_prompt = para_dict['Regional Prompt']\n",
    "negative_prompt = \"\" # negative_prompt, \n",
    "images = pipe(\n",
    "    prompt=regional_prompt,\n",
    "    split_ratio=split_ratio, # The ratio of the regional prompt, the number of prompts is the same as the number of regions\n",
    "    batch_size = 1, #batch size\n",
    "    base_ratio = 0.5, # The ratio of the base prompt    \n",
    "    base_prompt= None,       \n",
    "    num_inference_steps=20, # sampling step\n",
    "    height = 1024, \n",
    "    negative_prompt=negative_prompt, # negative prompt\n",
    "    width = 1024, \n",
    "    seed = 30,# random seed\n",
    "    guidance_scale = 7.0\n",
    ").images[0]\n",
    "images.save(\"test.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-03T21:39:00.492178Z",
     "iopub.status.busy": "2025-05-03T21:39:00.491850Z",
     "iopub.status.idle": "2025-05-03T21:39:00.501276Z",
     "shell.execute_reply": "2025-05-03T21:39:00.500507Z",
     "shell.execute_reply.started": "2025-05-03T21:39:00.492153Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting template/template.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile template/template.txt\n",
    "You are a master of composition who excels at extracting key objects and their attributes from input text and supplementing the original text with more detailed imagination, creating layouts that conform to human aesthetics. Your task is described as follows:\n",
    "\n",
    "Extract the key entities and their corresponding attributes from the input text, and determine how many regions should be splited.\n",
    "For each key object identified in the previous step, use precise spatial imagination to assign each object to a specific area within the image and start numbering from 0. The area refers to dividing the entire image into different regions for a general layout. Each key entities is assigned to a region. And for each entity in the region, give it a more detailed description based on the original text. This layout should segment the image and strictly follow the method below:\n",
    "a. Determine if the image needs to be divided into multiple rows (It should be noted that a single entity should not be split into different rows, except when describing different parts of a person like the head, clothes/body, and lower garment):\n",
    "• If so, segment the image into several rows and assign an identifier to each row from top to bottom (e.g., Row0, Row1, ...).\n",
    "• Specify the percentage of height each row occupies within the image (e.g., Row0 (height=0.33) indicates that the row occupies 33% of the height of the entire upper portion of the image).\n",
    "b. Within each row, further assess the need for division into multiple regions (it should be noted that each region should contain only one entity):\n",
    "• If required, divide each row from left to right into several blocks and assign a number to each block (e.g., Region0, Region1, ...).\n",
    "• Specify the percentage of width each block occupies within its respective row (e.g., Region0 (Row0, width=0.5) denotes that the block is located in Row0 and occupies 50% of the width of that row's left side).\n",
    "c. Output the overall ratio along with the regional prompts:\n",
    "• First, combine each row's height separated by semicolons like Row0_height; Row1_height; ...; Rown_height. If there is only one row, skip this step.\n",
    "• Secondly, attach each row's regions' width after each row's height separated with commas, like Row0_height,Row0_region0_width,Row0_region1_width,...Row0_regionm_width;Row1_height,Row1_region0_width,...;Rown_height,...Rown_regionj_width.\n",
    "• If the row doesn't have more than one region, just continue to the next row.\n",
    "• It should be noted that we should use decimal representation in the overall ratio, and if there is only one row, just omit the row ratio.\n",
    "• It should be noted that we should not use bold formatting or markdown-style syntax. The response should be plain text. The structure must match the examples below exactly. \n",
    "Regional Prompt Format Guidance:\n",
    "- After completing the layout planning and identifying the regional descriptions, format your output as follows:\n",
    "- Begin with the label `Regional Prompt:` followed by the descriptions for each region, in order.\n",
    "- Separate each region's description with the word `BREAK` in all caps.\n",
    "- Ensure each regional description is a vivid, imaginative narrative of that region’s entity based on the original caption.\n",
    "- Do not use markdown symbols, bold formatting, or bullet points.\n",
    "- Example format:\n",
    "Regional Prompt: Description of Region0 BREAK Description of Region1 BREAK Description of Region2 ...   \n",
    "The output should follow the format of the examples below:\n",
    "\n",
    "Examples:\n",
    "Caption: A green twintail hair girl wearing a white shirt printed with green apple and wearing a black skirt.\n",
    "Key entities identification:\n",
    "We only identify a girl with attribute: green hair twintail, red blouse, blue skirt, so we hierarchically split her features from top to down.\n",
    "1). green hair twintail (head features of the girl)\n",
    "2). red blouse (clothes and body features of the girl)\n",
    "3). blue skirt (Lower garment)\n",
    "So we need to split the image into 3 subregions.\n",
    "Plan the structure split for the image:\n",
    "a. Rows\n",
    "Row0(height=0.33): Top 33% of the image, which is the head of the green twintail hair girl\n",
    "Row1(height=0.33): Middle 33% part of the image, the body of the girl which is the red blouse part\n",
    "Row2(height=0.33): Bottom 33% part of the lower body of the girl, which is the blue skirt\n",
    "There is no need to split each row into different regions, so each row is a subregion\n",
    "b. Regions with rows:\n",
    "Region0:(Row0,width=1) Lush green twintails cascade down, framing the girl's face with lively eyes and a subtle smile, accented by a few playful freckles\n",
    "Region1: (Row1,width=1) A vibrant red blouse, featuring ruffled sleeves and a cinched waist, adorned with delicate pearl buttons, radiates elegance\n",
    "Region2: (Row2,width=1) pleated blue skirt, knee-length, sways gracefully with each step, its fabric catching the light, paired with a slender white belt for a touch of sophistication.\n",
    "c. Overall ratio:\n",
    "Row0_height,(Row0_region0_width only one region in the row, skip); Row1_height,(Row1_region1_width only one region in the row, skip); Row2_height,(Row2_region2_width only one region in the row, skip)\n",
    "Final split ratio: 1;1;1\n",
    "Regional Prompt: Lush green twintails cascade down, framing the girl's face with lively eyes and a subtle smile, accented by a few playful freckles BREAK A vibrant red blouse, featuring ruffled sleeves and a cinched waist, adorned with delicate pearl buttons, radiates elegance BREAK pleated blue skirt, knee-length, sways gracefully with each step, its fabric catching the light, paired with a slender white belt for a touch of sophistication.\n",
    "\n",
    "Caption: A girl with white ponytail and black dress are chatting with a blonde curly hair girl in a white dress in a cafe.\n",
    "Key entities identification:\n",
    "We only identify two girls each with two attributes, #girl1(white ponytail,black dress) #girl2(blonde curly hair,blue skirt) so we hierarchically split their features from top to down.\n",
    "white ponytail (head features of the girl on the left)\n",
    "black dress (clothes features of the girl on the left)\n",
    "blonde curly hair (head features of the girl on the right)\n",
    "blue skirt (clothes of the girl on the right)\n",
    "Plan the structure split for the image:\n",
    "So we need to split the image into 4 subregions.\n",
    "a. Rows\n",
    "Since we have four key entities, we should split the image into 4 different regions, and two rows, the girls’ head in the top row, the girls’ body in the bottom row\n",
    "Row0 (height=0.5): Encompasses the heads and upper torsos of both women.\n",
    "Row1 (height=0.5): Includes the lower torsos of both women, down to where the table cuts across the image.\n",
    "b. Regions within rows\n",
    "Region0 (Row0, width=0.5): White ponytail girl, focusing on her sleek, flowing hair and the subtle expression of engagement in her conversation..\n",
    "Region1 (Row0, width=0.5): Blonde curly hair girl, emphasizing her vibrant curls and the lively sparkle in her eyes as she engages in the chat.\n",
    "Region2 (Row1, width=0.5): Her elegant black dress, highlighting the fabric's texture and any intricate details, like lace or embroidery.\n",
    "Region3 (Row1, width=0.5):Her white dress, capturing its flowy silhouette, possibly with floral patterns or delicate folds to accentuate its elegance.\n",
    "c. Overall ratio:\n",
    "Row0_height,Row0_region0_width,Row0_region1_width;Row1_height,Row1_region2_width,Row1_region3_wdith\n",
    "Final split ratio: 1,1,1;1,1,1\n",
    "Regional Prompt: Captures the woman in the black dress within the top half of the image. BREAK Contains the woman in the white blouse within the top half. BREAK Shows the lower half of the woman in the black dress. BREAK Displays the lower half of the woman in the white blouse.\n",
    "\n",
    "Caption Two girls are chatting in the cafe \n",
    "Key entities identification:\n",
    "The caption identifies two key entities without explicit attributes:\n",
    "Girl 1 (human subject, unspecified attributes)\n",
    "Girl 2 (human subject, unspecified attributes)\n",
    "Since no specific attributes are given for either girl, we will need to imagine details for each entity. We will split the image into two regions to represent each girl.\n",
    "\n",
    "Plan the structure split for the image:\n",
    "a. Rows\n",
    "Considering that we have two key entities and no specific attributes to separate vertically, we can choose to have a single row that encompasses both entities:\n",
    "Row0 (height=1): This row will occupy the entire image, showing both girls chatting in the cafe.\n",
    "\n",
    "b. Regions within rows\n",
    "We will divide the row into two regions to represent each girl:\n",
    "\n",
    "Region0 (Row0, width=0.5): This region will capture Girl 1, who could be imagined as having a casual hairstyle and a comfortable outfit, seated with a cup of coffee, engaged in conversation.\n",
    "Region1 (Row0, width=0.5): This region will capture Girl 2, perhaps with a different hairstyle for contrast, such as a bun or waves, and a distinct style of clothing, also with a beverage, actively participating in the chat.\n",
    "\n",
    "c. Overall ratio:\n",
    "Since there is only one row, we omit the row ratio and directly provide the widths of the regions within the row:\n",
    "Final split ratio: 0.5,0.5\n",
    "\n",
    "Regional Prompt: A casually styled Girl 1 with a warm smile, sipping coffee, her attention focused on her friend across the table, the background softly blurred with the ambiance of the cafe. BREAK Girl 2, with her hair up in a loose bun, laughing at a shared joke, her hands wrapped around a steaming mug, the cafe's cozy interior framing their intimate conversation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-04T00:31:17.906348Z",
     "iopub.status.busy": "2025-05-04T00:31:17.905625Z",
     "iopub.status.idle": "2025-05-04T00:32:08.787690Z",
     "shell.execute_reply": "2025-05-04T00:32:08.786433Z",
     "shell.execute_reply.started": "2025-05-04T00:31:17.906321Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-04 00:31:20.205111: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1746318680.226143     630 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1746318680.232718     630 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
      "Token is valid (permission: fineGrained).\n",
      "Your token has been saved to /root/.cache/huggingface/token\n",
      "Login successful\n",
      "/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Loading pipeline components...: 100%|█████████████| 7/7 [00:02<00:00,  2.57it/s]\n",
      "🧠 Waiting for DeepSeekR1 response...\n",
      "✅ DeepSeekR1 response: **Final split ratio:** 0.5, 0.5  \n",
      "\n",
      "**Regional Prompt:** Axial FLAIR image of the suprasellar region, showing a lesion extending into the temporal lobes along the optic tracts, with moderate mass effect compressing adjacent structures, consistent with optic pathway glioma (arrows). BREAK Axial FLAIR sequence of the midbrain, revealing hyperintense signal in the left mesencephalon, indicating tumor infiltration beyond the optic pathways into the brainstem.\n",
      "❌ Final split ratio not found.\n",
      "✅ Regional Prompt: ** Axial FLAIR image of the suprasellar region, showing a lesion extending into the temporal lobes along the optic tracts, with moderate mass effect compressing adjacent structures, consistent with optic pathway glioma (arrows). BREAK Axial FLAIR sequence of the midbrain, revealing hyperintense signal in the left mesencephalon, indicating tumor infiltration beyond the optic pathways into the brainstem.\n",
      "Traceback (most recent call last):\n",
      "  File \"/kaggle/working/RPG-DiffusionMaster/RPG.py\", line 24, in <module>\n",
      "    raise ValueError(\"Model did not return a valid response. Check logs for details.\")\n",
      "ValueError: Model did not return a valid response. Check logs for details.\n"
     ]
    }
   ],
   "source": [
    "!python RPG.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-03T21:34:17.881008Z",
     "iopub.status.busy": "2025-05-03T21:34:17.880761Z",
     "iopub.status.idle": "2025-05-03T21:34:17.895915Z",
     "shell.execute_reply": "2025-05-03T21:34:17.895355Z",
     "shell.execute_reply.started": "2025-05-03T21:34:17.880987Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "os.chdir(\"/kaggle/working/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-03T21:34:17.896981Z",
     "iopub.status.busy": "2025-05-03T21:34:17.896745Z",
     "iopub.status.idle": "2025-05-03T21:34:27.775748Z",
     "shell.execute_reply": "2025-05-03T21:34:27.775145Z",
     "shell.execute_reply.started": "2025-05-03T21:34:17.896961Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/kaggle/working/output_folder.zip'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import shutil\n",
    "shutil.make_archive('/kaggle/working/output_folder', 'zip', '/kaggle/working/RPG-DiffusionMaster')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [],
   "dockerImageVersionId": 31011,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
